{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction = pd.read_csv('train_transaction.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "df_transaction.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleaning(object):\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.all_na = df.isnull().sum()/df.shape[0]\n",
    "\n",
    "    def clean_na(self,df):\n",
    "        self.less_na = all_na[all_na < 0.90]\n",
    "        return df.loc[:,less_na]\n",
    "    \n",
    "    def subset(self,df,index):\n",
    "        return df.iloc[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only small percentage of values are fraudalent.\n",
    "(df_transaction.isFraud.value_counts() / df_transaction.shape[0] ) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not removing columns simply because it has more NA\n",
    "#maybe more values in less number of rows can help us detect fraud\n",
    "#lets compare NAs in both tables fraud=0 and fraud=1\n",
    "df_isfraud_yes = df_transaction[df_transaction.isFraud==1]\n",
    "df_isfraud_no = df_transaction[df_transaction.isFraud==0]\n",
    "\n",
    "comparision = cleaning(df_isfraud_no)\n",
    "values_no = comparision.all_na.values\n",
    "comparision = cleaning(df_isfraud_yes)\n",
    "values_yes = comparision.all_na.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I computed percentage of na values in both fradualant and non fraudalent dataframe\n",
    "# this procudeure was to identify if let's say whole columns had 90% missing values\n",
    "# but rest 10% belongs to fraudalent dataset. That is why this was important to analyse indipendently\n",
    "pd.set_option('display.max_rows', 500)\n",
    "values = pd.DataFrame(values_no,values_yes).reset_index(inplace=False)\n",
    "values.columns = [\"fraud_no\",\"fraud_yes\"]\n",
    "values[\"difference\"] = ((values.fraud_no - values.fraud_yes) / values.fraud_no ) * 100 \n",
    "values.difference[values.difference.isna()] = 0\n",
    "values = values[(values.difference >= 0) & (values.fraud_no < 0.50) & (values.fraud_yes < 0.50)]\n",
    "index_values = values.index\n",
    "index_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I am calling the function subset in thr cleaning class\n",
    "comparision = cleaning(df_transaction)\n",
    "df_transaction = comparision.subset(df_transaction,index_values)\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times=[]\n",
    "\n",
    "def time_conversion(df):\n",
    "    for i in range(df.shape[0]):\n",
    "        t = df.TransactionDT[i]\n",
    "        t = datetime.datetime.fromtimestamp( t )\n",
    "        t = t.replace()\n",
    "        times.append(t)\n",
    "    df.TransactionDT = times\n",
    "    return df\n",
    "\n",
    "df_transaction = time_conversion(df_transaction)\n",
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.Series( (round((df_transaction.TransactionDT /(60*60)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = pd.Series(df_transaction.isFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_anomiles = pd.concat([time,anomalies],axis=1)\n",
    "plt.plot(time_anomiles.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_anomiles = pd.concat([time,anomalies],axis=1)\n",
    "time_anomiles = time_anomiles.groupby(\"TransactionDT\").sum().reset_index()\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(time_anomiles.TransactionDT,time_anomiles.isFraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_anomiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "t = 86458\n",
    "t = (datetime.datetime.fromtimestamp(t))\n",
    "t = t.replace()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try1 = df_transaction.iloc[:,1:10]\n",
    "try1 = try1.drop(\"ProductCD\",axis=1)\n",
    "try1.head()\n",
    "\n",
    "for i in range(2,(try1.shape[1]  )):\n",
    "    try1.iloc[:,i] = try1.iloc[:,i].fillna(try1.iloc[:,i].median())\n",
    "\n",
    "try1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class predictions(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def oversampeling(x,y):\n",
    "        smt = SMOTE()\n",
    "        x,y = smt.fit_sample(x,y)\n",
    "        return x,y\n",
    "    \n",
    "    def feature_selection(self,df,num_features):\n",
    "        df.fillna(0)\n",
    "        best = SelectKBest(chi2,num_features)\n",
    "        fit = best.fit(df.iloc[:,:-1],df.iloc[:,-1])\n",
    "        score = pd.DataFrame(fit.scores_)\n",
    "        cols = pd.DataFrame(df.columns)\n",
    "        fs = pd.concat([score,cols],axis=1)\n",
    "        fs.columns = [\"score\",\"col\"]\n",
    "        fs = fs.sort_values(\"score\",ascending=False)\n",
    "        top = fs[\"col\"]\n",
    "        df = df.loc[:,top]\n",
    "        return df\n",
    "    \n",
    "    def boosting(self,df):\n",
    "        train_x,test_x , train_y,test_y = train_test_split(df.iloc[:,:-1],df.isFraud,random_state=57,test_size=0.3)\n",
    "        smt = SMOTE()\n",
    "        train_x,train_y = smt.fit_sample(train_x,train_y)\n",
    "        \n",
    "        model = xgb.XGBClassifier()\n",
    "        model.fit(train_x,train_y)\n",
    "        pred_prob = model.predict_proba(test_x)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred = model.predict(test_x)\n",
    "        acc = accuracy_score(test_y,pred)\n",
    "        \n",
    "        auc = roc_auc_score(test_y,pred)\n",
    "        fpr, tpr, therashold = roc_curve(test_y,pred_prob)\n",
    "        report = classification_report(pred,test_y)\n",
    "        con_mat = confusion_matrix(test_y,pred)\n",
    "        \n",
    "        return auc, fpr,tpr,therashold, report, acc, con_mat\n",
    "        \n",
    "        \n",
    "    \n",
    "    def logistic(self,df):\n",
    "        #train_x,test_x , train_y,test_y = train_test_split(df.iloc[:,2:8],df.isFraud,random_state=57,test_size=0.3)\n",
    "        train_x,test_x , train_y,test_y = train_test_split(df.iloc[:,:-1],df.isFraud,random_state=57,test_size=0.3)\n",
    "        smt = SMOTE()\n",
    "        train_x,train_y = smt.fit_sample(train_x,train_y)\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(train_x,train_y)\n",
    "        pred_prob = model.predict_proba(test_x)\n",
    "        pred_prob = pred_prob[:,1]\n",
    "        pred = model.predict(test_x)\n",
    "        acc = accuracy_score(test_y,pred)\n",
    "        \n",
    "        auc = roc_auc_score(test_y,pred)\n",
    "        fpr, tpr, therashold = roc_curve(test_y,pred_prob)\n",
    "        report = classification_report(pred,test_y)\n",
    "        con_mat = confusion_matrix(test_y,pred)\n",
    "        return auc, fpr,tpr,therashold, report, acc, con_mat\n",
    "    \n",
    "    def randomforest(df):\n",
    "        train_x,test_x , train_y,test_y = train_test_split(df.iloc[:,2:8],df.isFraud,random_state=57,test_size=0.3)\n",
    "        model = RandomForestClassifier(n_estimators=50,max_depth=3,random_state=0)\n",
    "        model.fit(train_x,train_y)\n",
    "        pred = model.predict_proba(test_x)\n",
    "        #acc = accuracy_score(test_y,pred)\n",
    "        pred = pred[:,1]        \n",
    "        auc = roc_auc_score(test_y,pred)\n",
    "        fpr, tpr, therashold = roc_curve(test_y,pred)\n",
    "        return auc, fpr,tpr,therashold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions()\n",
    "df = pred.feature_selection(c_only,5)\n",
    "df[\"isFraud\"] = df_transaction.isFraud\n",
    "\n",
    "auc, fpr,tpr,therashold, report, accuracy, con_mat = pred.boosting(df)\n",
    "print(\"area under the curve{}\".format(auc))\n",
    "print(\"total accuracy{}\".format(accuracy))\n",
    "print(\"confusion matrix is{} \".format(con_mat))\n",
    "print(report)\n",
    "plt.plot([0,1],[0,1],linestyle=\"--\")\n",
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions\n",
    "\n",
    "accuracy =  predictions.logistic(try1)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross check fraud and productCD\n",
    "\n",
    "pd.crosstab(df_transaction.isFraud,df_transaction.ProductCD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_transaction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is difference between dimension reduction(PCA) and feature selection(RIDGE LASSO)\n",
    "# FEATURE SELECTION SHOULD BE PERFORMED IN EACH LOOP OF CROSS VALIDATION. \n",
    "#Do not perform feature selction only once and then use cross-validation, this will elad to overfitting.\n",
    "# correlation calclatino can also be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"kshitiz\",\"sirohi\",\" itraz\"]\n",
    "b = \"it\"\n",
    "for i in a:\n",
    "    print(b in i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= \"C\"\n",
    "columns_c = df_transaction.iloc[:,[True for i in df_transaction.columns if c in i ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try2 = df_transaction.iloc[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try2[\"isFraud\"] = df_transaction.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_only = try2.filter(like=\"C\")\n",
    "c_only[\"isFraud\"]= try2.isFraud\n",
    "\n",
    "d_only = try2.filter(like=\"D\")\n",
    "d_only[\"isFraud\"] = try2.isFraud\n",
    "d_only = d_only.fillna(0)\n",
    "\n",
    "m_only = try2.filter(like=\"M\")\n",
    "m_only[\"isFraud\"] = try2.isFraud\n",
    "m_only = m_only.fillna(0)\n",
    "\n",
    "v_only = try2.filter(like=\"V\")\n",
    "v_only[\"isFraud\"] =try2.isFraud\n",
    "v_only = v_only.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(v_only.iloc[:,:-1],v_only.isFraud,test_size=.3)\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model,100)\n",
    "#rfe = rfe.fit(trainx,trainy)\n",
    "print(rfe.support_)\n",
    "\n",
    "#model.fit(trainx,trainy)\n",
    "#pred = model.predict(testx)\n",
    "#acc = accuracy_score(pred,testy)\n",
    "#acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(testy,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "best = SelectKBest(chi2,4)\n",
    "fit = best.fit(c_only.iloc[:,:-1],c_only.iloc[:,-1])\n",
    "score = pd.DataFrame(fit.scores_)\n",
    "cols = pd.DataFrame(c_only.columns)\n",
    "fs = pd.concat([score,cols],axis=1)\n",
    "fs.columns = [\"score\",\"col\"]\n",
    "fs = fs.sort_values(\"score\",ascending=False)\n",
    "top100 = fs.head(30).col\n",
    "c_only = c_only.loc[:,top100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_only[\"isFraud\"]= df_transaction.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x , train_y,test_y = train_test_split(v_only.iloc[:,:-1],v_only.isFraud,random_state=57,test_size=0.3)\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(train_x,train_y)\n",
    "pred_prob = model.predict_proba(test_x)\n",
    "pred_prob = pred_prob[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
